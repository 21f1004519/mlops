{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "### Week 1 GA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO",
    "tags": []
   },
   "source": [
    "### Assignment Objective : \n",
    "\n",
    "\n",
    "Setting up the ML pipeline for IRIS Classifier in Vertex AI platform using GCS as demonstrated in the lecture (Hands-on: Introduction to Google Cloud, Vertex AI) in your GCP account.\n",
    "\n",
    "1) Activate your GCP Trial\n",
    "2) Setup Vertex AI Workbench (Enable appropriate services/api as required)\n",
    "3) Store Training Data in Google Storage Bucket \n",
    "4) Fetch the data from Google Storage Bucket and Successfully execute the IRIS Machine Learning Training Pipeline\n",
    "5) Store the Output artifacts(Models, logs, etc) in Google cloud storage bucket with folders organized by their training execution timestamp\n",
    "6) Create a new script for inference and run the inference on eval set after fetching the models from GCS Output Artifacts Bucket\n",
    "7) Run this Training and inference for 2 times resulting in two output artifact folders in Google cloud storage bucket\n",
    "8) (Optional) Run this pipeline for two versions of data provided in github data folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fe0bb78c9ce",
    "tags": []
   },
   "source": [
    "### Dataset\n",
    "We have a data folder that contains three subfolders: raw, v1, and v2.\n",
    "Inside the raw folder, there is a file named iris.csv, and inside the v1 and v2 folders, there is a file named data.csv respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0316df526f8"
   },
   "source": [
    "### Process starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9065e8d7f0fb"
   },
   "source": [
    "### Prerequisites "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4464,
     "status": "ok",
     "timestamp": 1752137477124,
     "user": {
      "displayName": "da5014 1",
      "userId": "01646375301695730652"
     },
     "user_tz": -330
    },
    "id": "1fd00fa70a2a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install Vertex AI SDK for Python and other required packages\n",
    "! pip3 install --upgrade --quiet  google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfEglUHQk9S3",
    "tags": []
   },
   "source": [
    "### Set Google Cloud project information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752137480955,
     "user": {
      "displayName": "da5014 1",
      "userId": "01646375301695730652"
     },
     "user_tz": -330
    },
    "id": "set_project_id",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"heroic-throne-473405-m8\"\n",
    "LOCATION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "### Create a Cloud Storage bucket to store the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752137488631,
     "user": {
      "displayName": "da5014 1",
      "userId": "01646375301695730652"
     },
     "user_tz": -330
    },
    "id": "bucket",
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://heroic-throne-473405-m8-week1ga\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2srkkUb6gOL7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://heroic-throne-473405-m8-week1ga/...\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://data/raw/iris.csv [Content-Type=text/csv]...\n",
      "/ [1 files][  3.8 KiB/  3.8 KiB]                                                \n",
      "Operation completed over 1 objects/3.8 KiB.                                      \n",
      "Copying file://data/v1/data.csv [Content-Type=text/csv]...\n",
      "/ [1 files][  2.5 KiB/  2.5 KiB]                                                \n",
      "Operation completed over 1 objects/2.5 KiB.                                      \n",
      "Copying file://data/v2/data.csv [Content-Type=text/csv]...\n",
      "/ [1 files][  1.3 KiB/  1.3 KiB]                                                \n",
      "Operation completed over 1 objects/1.3 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp data/raw/iris.csv {BUCKET_URI}/data/raw/\n",
    "!gsutil cp data/v1/data.csv {BUCKET_URI}/data/v1/\n",
    "!gsutil cp data/v2/data.csv {BUCKET_URI}/data/v2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3330b4f12a0d"
   },
   "source": [
    "### Initialize Vertex AI SDK for Python\n",
    "\n",
    "To get started using Vertex AI, we must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e088ea8cd4a0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3938f6d37a1"
   },
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e95ca1e5e07c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c2d091d9e73"
   },
   "source": [
    "## Decision Tree model\n",
    "Build a Decision Tree model on iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qvqSD5MDgOL8",
    "outputId": "45047f0d-064c-4bcc-9c6b-bde3ea150340",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.plotting import parallel_coordinates\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn import metrics\n",
    "from google.cloud import storage\n",
    "\n",
    "DATA_VERSION = \"v2\"  # change to \"raw\", \"v1\", or \"v2\"\n",
    "\n",
    "# Load data from GCS\n",
    "data_path = f\"{BUCKET_URI}/data/{DATA_VERSION}/data.csv\" if DATA_VERSION != \"raw\" else f\"{BUCKET_URI}/data/raw/iris.csv\"\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kFGdB85kgOL8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size = 0.4, stratify = data['species'], random_state = 42)\n",
    "X_train = train[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y_train = train.species\n",
    "X_test = test[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y_test = test.species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xxORpJRgOL8",
    "outputId": "72db1025-1834-4dcb-8934-416b8cb99ace",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Decision Tree is 1.000\n"
     ]
    }
   ],
   "source": [
    "mod_dt = DecisionTreeClassifier(max_depth = 3, random_state = 1)\n",
    "mod_dt.fit(X_train,y_train)\n",
    "prediction=mod_dt.predict(X_test)\n",
    "print('The accuracy of the Decision Tree is',\"{:.3f}\".format(metrics.accuracy_score(prediction,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd"
   },
   "source": [
    "### Upload model artifacts and custom code to Cloud Storage\n",
    "\n",
    "Before you can deploy your model for serving, Vertex AI needs access to the following files in Cloud Storage:\n",
    "\n",
    "* `model.joblib` (model artifact)\n",
    "\n",
    "Run the following commands to upload your files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current time\n",
    "timestamp = int(time.time())\n",
    "\n",
    "# Convert to readable string (YYYY-MM-DD_HH-MM-SS)\n",
    "timestamp_str = datetime.fromtimestamp(timestamp).strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "# Use that for artifact directory\n",
    "artifact_dir = f\"{BUCKET_URI}/artifacts/{DATA_VERSION}/{timestamp_str}/\"\n",
    "\n",
    "joblib.dump(mod_dt, \"model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ca67ee52d4d9",
    "outputId": "0567f4dc-db7d-44db-9120-d62897a7db97",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://model.joblib [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  2.2 KiB/  2.2 KiB]                                                \n",
      "Operation completed over 1 objects/2.2 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp model.joblib {artifact_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m133",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m133"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
